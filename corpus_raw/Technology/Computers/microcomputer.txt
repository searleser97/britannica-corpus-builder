Microcomputer,  an electronic device with a microprocessor as its central processing unit (CPU). Microcomputer was formerly a commonly used term for personal computers, particularly any of a class of small digital computers whose CPU is contained on a single integrated semiconductor chip. Thus, a microcomputer uses a single microprocessor for its CPU, which performs all logic and arithmetic operations. The system also contains a number of associated semiconductor chips that serve as the main memory for storing program instructions and data and as interfaces for exchanging data of this sort with peripheral devices (e.g., keyboard, video display, and printer) and auxiliary storage units. The earliest microcomputers marketed in the mid-1970s contained a single chip on which all CPU, memory, and interface circuits were integrated.
As large-scale integration and then very-large-scale integration progressively increased the number of transistors that could be placed on one semiconductor chip, so the processing capacity of microcomputers using such single chips grew commensurately. During the 1980s microcomputers came to be used widely in other applications besides electronic game systems and other relatively simple computer-based recreations. Increasingly powerful microcomputers began to be used in personal computer systems and workstations, for instance. High-performance microcomputer systems began to be used widely in business, in engineering, in “smart” or intelligent machines employed in the factory and office, and in military electronics systems.
