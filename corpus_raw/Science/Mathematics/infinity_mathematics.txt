Infinity,  the concept of something that is unlimited, endless, without bound. The common symbol for infinity, ∞, was invented by the English mathematician John Wallis in 1655. Three main types of infinity may be distinguished: the mathematical, the physical, and the metaphysical. Mathematical infinities occur, for instance, as the number of points on a continuous line or as the size of the endless sequence of counting numbers: 1, 2, 3,…. Spatial and temporal concepts of infinity occur in physics when one asks if there are infinitely many stars or if the universe will last forever. In a metaphysical discussion of God or the Absolute, there are questions of whether an ultimate entity must be infinite and whether lesser things could be infinite as well.
The ancient Greeks expressed infinity by the word apeiron, which had connotations of being unbounded, indefinite, undefined, and formless. One of the earliest appearances of infinity in mathematics regards the ratio between the diagonal and the side of a square. Pythagoras (c. 580–500 bce) and his followers initially believed that any aspect of the world could be expressed by an arrangement involving just the whole numbers (0, 1, 2, 3,…), but they were surprised to discover that the diagonal and the side of a square are incommensurable—that is, their lengths cannot both be expressed as whole-number multiples of any shared unit (or measuring stick). In modern mathematics this discovery is expressed by saying that the ratio is irrational and that it is the limit of an endless, nonrepeating decimal series. In the case of a square with sides of length 1, the diagonal is Square root of√2, written as 1.414213562…, where the ellipsis (…) indicates an endless sequence of digits with no pattern.
Both Plato (428/427–348/347 bce) and Aristotle (384–322 bce) shared the general Greek abhorrence of the notion of infinity. Aristotle influenced subsequent thought for more than a millennium with his rejection of “actual” infinity (spatial, temporal, or numerical), which he distinguished from the “potential” infinity of being able to count without end. To avoid the use of actual infinity, Eudoxus of Cnidus (c. 400–350 bce) and Archimedes (c. 285–212/211 bce) developed a technique, later known as the method of exhaustion, whereby an area was calculated by halving the measuring unit at successive stages until the remaining area was below some fixed value (the remaining region having been “exhausted”).
The issue of infinitely small numbers led to the discovery of calculus in the late 1600s by the English mathematician Isaac Newton and the German mathematician Gottfried Wilhelm Leibniz. Newton introduced his own theory of infinitely small numbers, or infinitesimals, to justify the calculation of derivatives, or slopes. In order to find the slope (that is, the change in y over the change in x) for a line touching a curve at a given point (x, y), he found it useful to look at the ratio between dy and dx, where dy is an infinitesimal change in y produced by moving an infinitesimal amount dx from x. Infinitesimals were heavily criticized, and much of the early history of analysis revolved around efforts to find an alternate, rigorous foundation for the subject. The use of infinitesimal numbers finally gained a firm footing with the development of nonstandard analysis by the German-born mathematician Abraham Robinson in the 1960s.
A more direct use of infinity in mathematics arises with efforts to compare the sizes of infinite sets, such as the set of points on a line (real numbers) or the set of counting numbers. Mathematicians are quickly struck by the fact that ordinary intuitions about numbers are misleading when talking about infinite sizes. Medieval thinkers were aware of the paradoxical fact that line segments of varying lengths seemed to have the same number of points. For instance, draw two concentric circles, one twice the radius (and thus twice the circumference) of the other, as shown in the figure. Surprisingly, each point P on the outer circle can be paired with a unique point P′ on the inner circle by drawing a line from their common centre O to P and labeling its intersection with the inner circle P′. Intuition suggests that the outer circle should have twice as many points as the inner circle, but in this case infinity seems to be the same as twice infinity. In the early 1600s, the Italian scientist Galileo Galilei addressed this and a similar nonintuitive result now known as Galileo’s paradox. Galileo demonstrated that the set of counting numbers could be put in a one-to-one correspondence with the apparently much smaller set of their squares. He similarly showed that the set of counting numbers and their doubles (i.e., the set of even numbers) could be paired up. Galileo concluded that “we cannot speak of infinite quantities as being the one greater or less than or equal to another.” Such examples led the German mathematician Richard Dedekind in 1872 to suggest a definition of an infinite set as one that could be put in a one-to-one relationship with some proper subset.
The confusion about infinite numbers was resolved by the German mathematician Georg Cantor beginning in 1873. First Cantor rigorously demonstrated that the set of rational numbers (fractions) is the same size as the counting numbers; hence, they are called countable, or denumerable. Of course this came as no real shock, but later that same year Cantor proved the surprising result that not all infinities are equal. Using a so-called “diagonal argument,” Cantor showed that the size of the counting numbers is strictly less than the size of the real numbers. This result is known as Cantor’s theorem.
To compare sets, Cantor first distinguished between a specific set and the abstract notion of its size, or cardinality. Unlike a finite set, an infinite set can have the same cardinality as a proper subset of itself. Cantor used a diagonal argument to show that the cardinality of any set must be less than the cardinality of its power set—i.e., the set that contains all the given set’s possible subsets. In general, a set with n elements has a power set with 2n elements, and these two cardinalities are different even when n is infinite. Cantor called the sizes of his infinite sets “transfinite cardinals.” His arguments showed that there are transfinite cardinals of endlessly many different sizes (such as the cardinals of the set of counting numbers and the set of real numbers).
The transfinite cardinals include aleph-null (the size of the set of whole numbers), aleph-one (the next larger infinity), and the continuum (the size of real numbers). These three numbers are also written as ℵ0, ℵ1, and c, respectively. By definition ℵ0 is less than ℵ1, and by Cantor’s theorem ℵ1 is less than or equal to c. Along with a principle known as the axiom of choice, the proof method of Cantor’s theorem can be used to ensure an endless sequence of transfinite cardinals continuing past ℵ1 to such numbers as ℵ2 and ℵℵ0.
The continuum problem is the question of which of the alephs is equal to the continuum cardinality. Cantor conjectured that c = ℵ1; this is known as Cantor’s continuum hypothesis (CH). CH can also be thought of as stating that any set of points on the line either must be countable (of size less than or equal to ℵ0) or must have a size as large as the entire space (be of size c).
In the early 1900s a thorough theory of infinite sets was developed. This theory is known as ZFC, which stands for Zermelo-Fraenkel set theory with the axiom of choice. CH is known to be undecidable on the basis of the axioms in ZFC. In 1940 the Austrian-born logician Kurt Gödel was able to show that ZFC cannot disprove CH, and in 1963 the American mathematician Paul Cohen showed that ZFC cannot prove CH. Set theorists continue to explore ways to extend the ZFC axioms in a reasonable way so as to resolve CH. Recent work suggests that CH may be false and that the true size of c may be the larger infinity ℵ2.
