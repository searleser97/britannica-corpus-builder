Evidence-based policy,  public policies, programs, and practices that are grounded in empirical evidence. The movement for evidence-based policy is an outgrowth of a movement in the United Kingdom in the 1990s calling for “evidence-based medicine,” which argued that only those treatment modalities (such as drugs) that are grounded in laboratory (experimental) evidence should be used. The concept and its arguments can be linked to older, 1970s-era concerns for a proper evaluation of policy outcomes. They also appear tied, however, to the much broader contemporary organizational and management studies concerned with knowledge and learning in organizations and whether such organizational knowing and learning can be managed.
The evidence-based policy movement in various public policy issues and other areas of practice originated in the United Kingdom, according to the preponderance of published work, in the context of medical practices. At stake was the professional practice of administering various medical treatments whose application and use were not necessarily grounded in empirical research—specifically, in the randomized controlled trials (RCTs) that serve as the basis for experimental testing in medicine and other such areas.
As the movement spread beyond medicine to other policy issue areas and beyond the United Kingdom to the United States, Australia, and elsewhere, various policies and practices came under attack for their lack of grounding—as their critics claimed—in empirical research. In some sense, the evidence-based movement might be seen as a reiteration of the 1960s and 1970s call for enhanced accountability by public-sector organizations, especially in policy implementation by local governmental organizations, that led to institutionalizing various forms of assessment within the policy cycle—a desire to know that governmental funding (taxpayers’ sterling or dollars or euros) was achieving desired ends. The evidence-based movement was a renewed call for accountability through a particular kind of policy and program evaluation, although using different terminology and instituted before implementation rather than during or after it.
The effort to connect social scientific knowledge with policy programs and practices is certainly desirable. Policy evaluation efforts have had their own difficulties, however, including problems in measurement and problems in determining what is capable of being assessed. The periodic expression of frustration with seemingly intractable or insoluble social problems led scholars to turn to questions of knowledge and its management and to pursue evidence as a more solid ground for policy research. There has, however, been little reflexivity in the midst of these debates. Proponents of evidence-based policy have, on the whole, used the term uncritically, as if there were only one sort of evidence that can produce scientific results. The kind of evidence they adduce is experimental evidence expressed through statistical analyses—not surprising, perhaps, given the movement’s origins in medical practices where experimentation is much at home. However, the experimental and statistical character of evidence assumed in this usage excludes observational evidence derived from local knowledge that emerges from the lived experience of participants in the situation under study, such as might be obtained through clinical or field research.
In issue areas other than physical medicine where evidence-based movements have developed, such as mental health, education, welfare, and criminal justice, it is not always possible to conduct RCTs, and so policies, programs, and practices do not—and cannot—rest on the same sort of evidentiary claims. For example, county-based mental health departments in the United States were called to task for administering psychotherapeutic interventions for troubled children without empirical evidence for their effectiveness, even though these programs had been used for several years with demonstrated case-by-case clinical success. One reading of U.S. President George W. Bush’s administration’s No Child Left Behind educational policy—which mandated schoolwide testing at several grades and tied funding to test-based performance—sees it as an effort to institute evidentiary grounding for teaching practices. One analyst noted that a specific research report reviewing this policy refers more than 100 times to scientifically based research supporting its claims, without, however, ever defining what it means to be scientifically based or discussing who should conduct such research. Contemporary welfare policy reforms may be seen similarly. The 1996 U.S. Personal Responsibility and Work Opportunity Reconciliation Act may be understood as an effort to ground federal assistance in demonstrable evidence that financial and other support were achieving their intended goals.
Although observational methods such as those used in field research follow the scientific canons of interpretive research, the dominant understanding of evidence in the context of policy practices does not include clinical observations such as those made by teachers in classrooms or social workers and therapists in counseling sessions, or field research observations such as those made by participant-observers or ethnographers doing community studies. In these and other nonmedical policy issue areas, such as welfare and education, experimentation is much less common—and its use might violate the protection of human subjects principles that have been encoded in much social scientific research ethics and practices. Other types of study that yield statistical analyses, such as attitude and other surveys, might also not be appropriate ways to address relevant research questions. This makes the narrowing of the domain of what constitutes acceptable evidence problematic.
Without explicit discussion of what constitutes scientific evidence, there is little discussion of what constitutes validation of research findings. Critics of evidence-based policy note that evidence derived from experiment-based observations (methodologically positivist procedures) is allowed into the arena of discourse and debate whereas evidence derived from field-based observations (methodologically interpretive procedures, for example from local knowledge emerging from the lived experience of participants in the situation under study) is implicitly disallowed. That clinical and interpretive research also follows indicators of trustworthiness (the equivalent of validity and reliability in the context of experimental research design) that are different from those used in experimental research has not become part of the evidentiary conversation. This unreflective use of evidence narrows the range of otherwise accepted and legitimate scientific procedures for conducting research.
